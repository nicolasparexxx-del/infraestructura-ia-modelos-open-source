apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-models-config
  namespace: ai-models
  labels:
    app: ai-models
data:
  # Configuración de la aplicación
  app.yaml: |
    app:
      name: "AI Models Infrastructure"
      version: "1.0.0"
      debug: false
      log_level: "INFO"

    models:
      cache_dir: "/app/models"
      max_memory_gb: 32.0
      auto_cleanup: true
      cleanup_interval: 3600

    inference:
      batch_size: 8
      max_concurrent: 10
      timeout: 300

    monitoring:
      enabled: true
      metrics_port: 8000
      health_check_interval: 30

    security:
      enable_auth: true
      rate_limit: 1000
      cors_origins: ["*"]

  # Configuración de logging
  logging.yaml: |
    version: 1
    disable_existing_loggers: false
    formatters:
      standard:
        format: '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
      json:
        format: '{"timestamp": "%(asctime)s", "level": "%(levelname)s", "logger": "%(name)s", "message": "%(message)s"}'
    handlers:
      console:
        class: logging.StreamHandler
        level: INFO
        formatter: standard
        stream: ext://sys.stdout
      file:
        class: logging.handlers.RotatingFileHandler
        level: DEBUG
        formatter: json
        filename: /app/logs/app.log
        maxBytes: 10485760
        backupCount: 5
    loggers:
      api:
        level: DEBUG
        handlers: [console, file]
        propagate: false
      model_manager:
        level: DEBUG
        handlers: [console, file]
        propagate: false
    root:
      level: INFO
      handlers: [console]

  # Lista de modelos populares
  popular_models.json: |
    {
      "text_generation": [
        "mistralai/Mistral-7B-v0.1",
        "meta-llama/Llama-2-7b-chat-hf",
        "tiiuae/falcon-7b-instruct",
        "microsoft/DialoGPT-large",
        "EleutherAI/gpt-neox-20b",
        "bigscience/bloom-7b1",
        "google/flan-t5-xxl",
        "databricks/dolly-v2-12b",
        "Writer/palmyra-base",
        "stabilityai/stablelm-base-alpha-7b"
      ],
      "text_classification": [
        "cardiffnlp/twitter-roberta-base-sentiment-latest",
        "distilbert-base-uncased-finetuned-sst-2-english",
        "facebook/bart-large-mnli",
        "microsoft/DialoGPT-medium",
        "nlptown/bert-base-multilingual-uncased-sentiment"
      ],
      "image_generation": [
        "runwayml/stable-diffusion-v1-5",
        "stabilityai/stable-diffusion-2-1",
        "stabilityai/stable-diffusion-xl-base-1.0",
        "dreamlike-art/dreamlike-diffusion-1.0",
        "wavymulder/Analog-Diffusion"
      ],
      "image_classification": [
        "google/vit-base-patch16-224",
        "microsoft/resnet-50",
        "facebook/convnext-base-224-22k-1k",
        "openai/clip-vit-base-patch32",
        "timm/efficientnet_b0.ra_in1k"
      ],
      "speech_recognition": [
        "openai/whisper-base",
        "facebook/wav2vec2-base-960h",
        "microsoft/speecht5_asr",
        "facebook/hubert-base-ls960",
        "jonatasgrosman/wav2vec2-large-xlsr-53-english"
      ]
    }

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: ai-models
  labels:
    app: prometheus
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      external_labels:
        cluster: 'ai-models-cluster'

    rule_files:
      - "alerts.yml"

    scrape_configs:
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']

      - job_name: 'ai-models-api'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - ai-models
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app]
            action: keep
            regex: ai-models-api
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__

      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - source_labels: [__address__]
            regex: '(.*):10250'
            replacement: '${1}:9100'
            target_label: __address__

      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)

      - job_name: 'gpu-metrics'
        static_configs:
          - targets: ['nvidia-dcgm-exporter:9400']

  alerts.yml: |
    groups:
      - name: ai-models-alerts
        rules:
          - alert: HighCPUUsage
            expr: cpu_usage_percent > 80
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High CPU usage detected"
              description: "CPU usage is above 80% for more than 5 minutes"

          - alert: HighMemoryUsage
            expr: memory_usage_percent > 85
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High memory usage detected"
              description: "Memory usage is above 85% for more than 5 minutes"

          - alert: GPUMemoryHigh
            expr: gpu_memory_usage_percent > 90
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: "GPU memory usage critical"
              description: "GPU memory usage is above 90%"

          - alert: ModelLoadingFailed
            expr: increase(model_loading_failures_total[5m]) > 3
            for: 1m
            labels:
              severity: critical
            annotations:
              summary: "Multiple model loading failures"
              description: "More than 3 model loading failures in the last 5 minutes"

          - alert: InferenceLatencyHigh
            expr: inference_duration_seconds{quantile="0.95"} > 30
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High inference latency"
              description: "95th percentile inference latency is above 30 seconds"

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-config
  namespace: ai-models
  labels:
    app: grafana
data:
  datasources.yaml: |
    apiVersion: 1
    datasources:
      - name: Prometheus
        type: prometheus
        access: proxy
        url: http://prometheus-service:9090
        isDefault: true
        editable: true

  dashboards.yaml: |
    apiVersion: 1
    providers:
      - name: 'default'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards

  grafana.ini: |
    [analytics]
    check_for_updates = true

    [grafana_net]
    url = https://grafana.net

    [log]
    mode = console
    level = info

    [paths]
    data = /var/lib/grafana/
    logs = /var/log/grafana
    plugins = /var/lib/grafana/plugins
    provisioning = /etc/grafana/provisioning

    [server]
    protocol = http
    http_port = 3000
    domain = localhost
    enforce_domain = false
    root_url = %(protocol)s://%(domain)s:%(http_port)s/
    router_logging = false
    static_root_path = public
    enable_gzip = false
    cert_file =
    cert_key =
    socket =

    [database]
    type = sqlite3
    host = 127.0.0.1:3306
    name = grafana
    user = root
    password =
    url =
    ssl_mode = disable
    path = grafana.db
    max_idle_conn = 2
    max_open_conn =
    conn_max_lifetime = 14400
    log_queries =

    [users]
    allow_sign_up = false
    allow_org_create = false
    auto_assign_org = true
    auto_assign_org_id = 1
    auto_assign_org_role = Viewer
    verify_email_enabled = false
    login_hint = email or username
    default_theme = dark

    [auth]
    login_cookie_name = grafana_session
    login_maximum_inactive_lifetime_duration =
    login_maximum_lifetime_duration =
    token_rotation_interval_minutes = 10
    disable_login_form = false
    disable_signout_menu = false
    signout_redirect_url =
    oauth_auto_login = false
    api_key_max_seconds_to_live = -1

    [security]
    admin_user = admin
    admin_password = admin123
    secret_key = SW2YcwTIb9zpOOhoPsMm
    disable_gravatar = false
    data_source_proxy_whitelist =
    disable_brute_force_login_protection = false
    cookie_secure = false
    cookie_samesite = lax
    allow_embedding = false
    strict_transport_security = false
    strict_transport_security_max_age_seconds = 86400
    strict_transport_security_preload = false
    strict_transport_security_subdomains = false
    x_content_type_options = true
    x_xss_protection = true
